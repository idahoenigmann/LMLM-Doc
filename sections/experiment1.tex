\chapter{Experiment 1}
\label{cap:experiment1}

\textbf{Author: Peter Kain} 

The first experiment tests whether the trained neural network from Section~\ref{sec:implementation_neural_network} generalises to other objects. Since it is impossible to train the neural network for all existing objects, this experiment tests if the neural network can, by learning from one object, determine the distance to other objects as well.

\section{Setup and Environment}
The addition of the third convolutional layer (see Fig.~\ref{pic:implementation_neuralNetwork_modificationsToTheNN_model}) allowed to solve problems of a higher complexity, as compared to before. For this experiment the neural network was further developed to attain a colour image as an input and output the corresponding x-, y- and z-coordinate. These changes dramatically increased the number of parameters and therefore the need for RAM and computation power. 

The best system available at that time was equipped with a NVIDIA 2080 TI, which has 11 GB of VRAM (or "video random access memory"). To also fully take advantage of the CUDA cores (parallel processors for graphical computing), the authors decided to use Tensorflow with the GPU only. These changes resulted in much greater performance than before (10s to train with ten images on the previous configuration opposed to 0.32s on the current one). One disadvantage of this solution is, that only the GPU is used for computing, which means that only the VRAM can be used. But, since the performance was so much better, it was worth it to lower the batch size from 40 to 20 images at a time, which, after testing, is the optimal value and uses about 10.8 of the 11 GB of VRAM available.

\section{Sequence of Events}
To train the neural network, the authors chose the monkey head object, as depicted in Figure~\ref{pic:implementation_generatingData_testObject}. This neural network is trained exclusively on the monkey head until the mean error is confirmed to be less than 10\%. For training the authors use 500 distinct images each for monkey heads of 5 different sizes, totalling in 2500 images.

After the neural network has been trained and reached a respectable accuracy of around 85\%, the authors will then test the neural network with images of another object. This object can again be seen in Figure~\ref{pic:implementation_generatingData_testObject}. Because we are not training with these images, only 50 images for each of the 5 sizes are evaluated. First the training aspect (changing the weights of the neural network according to the new input) will be disabled, allowing the authors to figure out the accuracy of the neural network when viewing new images for the first time, without changing the neural network itself.

Then the training aspect will be enabled again and the time and effort needed to reach an accuracy of under 15\% when retraining exclusively for the new object with the already pre-trained weights will be measured.

\vspace{5mm}
\noindent
\textbf{Author: Ida HÃ¶nigmann}

\section{Results}
After training the neural network with the monkey head object, the data predicted by the neural network for the vase object differed from the actual values as the following table depicts:

\begin{table}[h!]
	\begin{tabular}{ll|l}
		&     & \textbf{Difference in meters} \\
		\hline
		\textbf{average error} & x   & 3.023                         \\
		& y   & 0.443                         \\
		& z   & 3.18                          \\
		& \textbf{average} & \textbf{2.215}                         \\
		\hline
		\textbf{minimum error} & x   & 0.011                         \\
		& y   & 0.011                         \\
		& z   & 2.259                         \\
		\hline
		\textbf{maximum error} & x   & 6.577                         \\
		& y   & 1.224                         \\
		& z   & 7.132                                                  
	\end{tabular}
	\caption{Aggregated predictions of the neural network for all vase images.}
\end{table}

So overall this resulted in an average error of 2.215 meters.

The time needed to train the neural network with the vase images, which resulted in the desired accuracy of more than 85\%, was 40.62 seconds, training with 1220 images of the vase object.

The history of the loss values during the training on the vase images can be seen in Fig.~\ref{pic:experiment1_results_loss_and_percentageLoss}. This function is decaying exponentially, but it can be seen that the horizontal asymptote is relatively high. The same is true for the mean absolute percentage error over time. This means that there will always be some error and the maximum reachable accuracy is not 100\%. This was expected, as not even humans are able to judge distance with 100\% accuracy. Additionally the loss periodically jumps to a high value. This can be explained by a ''faulty'' image in the data, as depicted in Figure~\ref{pic:experiment1_results_faultyImage}, which is used as training data periodically as the images are not used in a random, but rather in a sequential order.

\begin{figure*}[h!]
	\centering
	\begin{subfigure}[t]{0.8\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/experiment1_results_lossOverTime.png}
		\caption{Loss over time when training with the vase images.}
	\end{subfigure}
	~ 
	\begin{subfigure}[t]{0.8\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/experiment1_results_MeanAbsolutePercentageErrorOverTime.png}
		\caption{Mean absolute percentage error over time when training with the vase images}
	\end{subfigure}
	\caption{Both, the loss and the mean absolute percentage error, decrease over time which means the predictions on vase images are getting more and more accurate.}
	\label{pic:experiment1_results_loss_and_percentageLoss}
\end{figure*}

\begin{figure*}[h!]
	\centering
	\includegraphics[width=\textwidth]{img/experiment1_results_faultyImg.jpg}
	\caption{One of the occasional faulty images. This is caused by the camera view intersecting with some objects also present in the Blender scene such as the monkey head object or the wall.}
	\label{pic:experiment1_results_faultyImage}
\end{figure*}

\section{Lessons Learned}
Looking back the most time consuming part of the Tensorflow implementation was modifications to the already existing neural network of Section~\ref{sec:implementation_neural_network}. This could have been avoided if the authors would have developed the prototype with the new hardware, where this experiment was run on, but this hardware was unavailable at the time of working on Section~\ref{sec:implementation_neural_network}, so in the future the authors will try to perform all preparations, including developing the prototype, on the same machine used in experiments.

Training a neural network with many different objects before ''showing'' it a new one could have helped improving the accuracy in this experiment. Therefore the authors recommend everyone to train on images of various objects, when the final image is not known in advance. If however, the object is known, as in the situation described in Section~\ref{sec:introduction_motivation}, training can be done specifically for the situation.

\filbreak
