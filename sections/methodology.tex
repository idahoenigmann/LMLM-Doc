\chapter{Methodology}

\textbf{Author: } 

\section{Challenges in the Use of Stereo Cameras}
Since many drones used in educational robotics can only carry a limited amount of weight it is not possible to attach a stereo camera to such a robot. Instead the functionality of a stereo camera on such a drone system can be mimicked by taking the first image, flying to a second position, located horizontally next to the first one and taking the second image. This process in not as precise as a stereo camera, where the two lenses are always positioned at an exact interval from one another. Therefore the output of this system might not work as reliable. Additionally other factors, such as differences in the two images due to some time passing between the taking of the images can have an effect on the accuracy.

Therefore the authors try to approach this challenge from the machine learning point of view. Neural networks can be taught to work with different changes in the environment and still return results with superior quality as opposed to a conventional implementation.

\section{Generating Data}
Neural Networks require huge amounts of data to work reliably. Because of the author's limited time frame this test data will be generated with the help of Blender 2.8. Blender is a free program for designing and animating 3D objects, which also supports scripting with Python to add or remove objects from a scene. The authors will use this capability to generate the huge amounts of test data needed from the perspectives of the two cameras, which point to a specific object in the scene. This enables the authors create enough images to train a neural network, since shooting the amount of pictures needed by hand would take too long to consider. 

\subsection{Blender}
Besides 3D-modelling Blender enables the user to perform various different actions, such as laying out scenes, UV-Editing, shading, animating and rendering. Additionally scenes can be modified by executing Python scripts. Figure~\ref{pic:methodology_generatingData_blender_startscreen} shows the interface of Blender 2.8 with the default file loaded.

\begin{figure}[h!]
	\centering
	\includegraphics[width=6.5in]{img/methodology_generatingData_blender_startscreen.png}
	\caption{Blender interface after startup. The default scene features a grey cube, a camera (left of the cube) and a light source (black dot and circle positioned on the top right of the cube).}
	\label{pic:methodology_generatingData_blender_startscreen}
\end{figure}

The authors decided to extensively use the scripting function in their work. One example of a Python script, that can be executed in Blender is the following code:

\begin{lstlisting}[language=python]
import bpy

# Selects all cubes and deletes them
bpy.ops.object.select_all(action='DESELECT')
bpy.ops.object.select_by_type(type='MESH')
bpy.ops.object.delete()

# Adds a new cube
bpy.ops.mesh.primitive_cube_add(size=3, enter_editmode=False, location=(4, 2, 0))

# Adds a new material representing the colour red
bpy.ops.material.new()
material = bpy.data.materials[-1]
material.name = 'Red'
material.diffuse_color = (0.8, 0.1, 0.1, 1)

# Apply material onto the newly created cube object
bpy.context.active_object.data.materials.append(material)
\end{lstlisting}

This code first clears the scene from other meshes (running the script twice would otherwise place the new cube inside the old cube). Then a new mesh in form of a cube is added at the given location. Next colour is added to the new cube by applying a material. A material is a specification of how the surface of the object should look. Advanced materials can represent raw or reflective surfaces, however the authors decided to keep it simple. The chosen material represents a red surface (the red/green/blue/alpha channels ranging from 0.0 (for 0) to 1.0 (for 255) are specified). Lastly the created material is applied to the object. The final result can be seen below:

\begin{figure}[h!]
	\centering
	\includegraphics[width=6.5in]{img/methodology_generatingData_blender_exampleScriptResult.png}
	\caption{The result of the above code. After the default cube is deleted, a new one is added with a red material and translated via the 'location' argument.}
	\label{pic:methodology_generatingData_blender_exampleScriptResult}
\end{figure}

Using similar Python scripts the authors will generate the image data necessary as well as perform the calculation of the distance which will be specified as the correct values to train the neural network on.

\section{Image Preprocessing}
After the test images have been rendered with the help of Blender some image preprocessing is required. For example the machine learning component of this project should take two images as an input. To simplify the input the two images will be placed next to each other to form a new image twice as wide as the original images. This process is visualized in Figure~\ref{pic:methodology_imagePreprocessing_imageMerge}. Other preprocessing measures that have to be taken are downscaling the image, as to not have too many weights in the first layer of the neural network.

\begin{figure}[h!]
	\centering
	\includegraphics[width=6.5in]{img/methodology_imagePreprocessing_imageMerge.png}
	\caption{Two greyscale renders showing the same object from two different camera positions in Blender are merged into one picture which can be feed into the neural network component.}
	\label{pic:methodology_imagePreprocessing_imageMerge}
\end{figure}

Additionally, the authors decided to experiment if manipulating these test images further would result in differences of distance perception by the neural network or if they would speed up or slow down the learning phase. These manipulations are done using OpenCV and Python3. OpenCV provides many image manipulation tools. For this project the authors chose the following methods of image manipulation:

\begin{table}[h!]
	\begin{tabular}{|l|l|}
		\hline
		\bfseries Name & \bfseries Description \\
		\hline
		Greyscale & A greyscale image is an image with only one value for the red, green and \\
		& blue colour channels, resulting in different shades of grey instead of usual \\
		& colours. \\
		\hline
		Resolution & Resolution refers to the number of pixels placed in each dimension \\
		& (width and height). \\
		\hline
		Cropping & When cropping an image an unwanted part located at the peripheral areas \\
		& of the image is removed. \\
		\hline
		Saturated & Saturated images feature stronger colours, which makes them easier to \\
		& distinguish from another. \\
		\hline
		Brightness & Brightening images can make colours harder to distinguish from another. \\
		& Additionally it can lead to the same problems encountered in overexposed \\
		& images, such as part of the image being completely white and therefore not \\
		& providing any information. \\
		\hline
	\end{tabular}
\end{table}


\section{Neural Network}
A neural network is a tool used in machine learning. It consists of nodes, each receiving some input values as well as some weights associated to each input value and outputs some output value. The calculation returning the output value is relatively simple. Many of these nodes form what is called a layer. By forming multiple connections between the nodes the neural network can perform more complex tasks. A vanilla neural network consists of multiple layers, where each node receives all output values of all nodes in the previous layer as an input. A visualization of a vanilla neural network can be seen in Figure~\ref{pic:methodology_neuralNetwork_visualizationOfANN}. By manipulating the weights associated to each input value the network can learn to solve a given task.

\begin{figure}[h!]
	\centering
	\includegraphics[width=4.5in]{img/methodology_neuralNetwork_visualizationOfANN.png}
	\caption{Depiction af a vanilla neural network. Each circle represents a node and the arrows show the flow of information. All nodes on the same level are collectively called a layer.}
	\label{pic:methodology_neuralNetwork_visualizationOfANN}
\end{figure}

\subsection{Convolutional Neural Network}
One of the disadvantages of neural networks is that they need huge amounts of data in order to optimize the values of all weights. Therefore a modified version of neural networks was invented. Convolutional neural networks simplify the optimization of the weights by stating that some weights are shared between multiple connections of nodes. This results in fewer weights having to be optimized. Additionally convolutional neural networks perform similar actions in multiple parts of the input data which especially makes sense when working with images, e.g. search for edges in all sections of an image.

\begin{figure}[h!]
	\centering
	\includegraphics[width=3.5in]{img/methodology_neuralNetwork_visualizationOfACNN.png}
	\caption{Segment of a convolutional neural network. In comparison to a vanilla neural network each node is only connected to its closest neighbours. Additionally all arrows connected to another node in the same relative position (same colour) have the same weight attached.}
	\label{pic:methodology_neuralNetwork_visualizationOfACNN}
\end{figure}

\newpage

\subsection{Loss Function}
A loss function is used in optimization problems to determine the loss or cost of some operation. Therefore a low loss is desired. Some loss functions commonly used in machine learning are:

\subsubsection{Mean Squared Error}
\begin{displaymath}
mse = \frac{1}{n} \sum_{i=1}^{n} (x_i - \hat{x}_i)^2
\end{displaymath}

where $n$ is the number of elements, $x$ is the correct value and $\hat{x}$ is the estimated value. Squaring the difference of the correct and estimated value is necessary, as negative and positive differences could otherwise annul each other.

\subsubsection{Mean Absolute Error}
\begin{displaymath}
mae = \frac{1}{n} \sum_{i=1}^{n} \abs{\hat{x}_i - x_i}
\end{displaymath}

where $n$ is the number of elements, $x$ is the correct value and $\hat{x}$ is the estimated value. In comparison to the mean squared error, this method uses the absolute value of the difference.

\subsubsection{Mean Absolute Percentage Error}
\begin{displaymath}
mape = \frac{100\%}{n}\sum_{i=1}^{n}\abs{\frac{x_i - \hat{x}_i}{x_i}}
\end{displaymath}

where $n$ is the number of elements, $x$ is the correct value and $\hat{x}$ is the estimated value. The mean absolute percentage error returns the average percentage by which the estimated value differs from the actual one.

\subsubsection{Mean Squared Logarithmic Error}
\begin{displaymath}
msle = \frac{1}{n} \sum_{i=1}^{n} log(\hat{x}_i + 1) - log(x_i + 1)
\end{displaymath}

where $n$ is the number of elements, $x$ is the correct value and $\hat{x}$ is the estimated value.

\subsubsection{Logcosh}

\subsubsection{Kullback Leibler Divergence}

\subsection{Activation Function}
The activation function defines the output of a node based on the input values it receives. Some of the most widely used activation functions are displayed in Fig.~\ref{pic:methodology_neuralNetwork_activationFunction1} and Fig.~\ref{pic:methodology_neuralNetwork_activationFunction2}.

\begin{figure*}[h!]
	\centering
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_activationFunction_elu.png}
		\caption{The Exponential Linear Unit function is defined as $f(\alpha, x) = \begin{cases} x & x \geq 0 \\ \alpha (e^x - 1) & x < 0 \end{cases}$.}
	\end{subfigure}%
	~ 
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_activationFunction_softplus.png}
		\caption{The SoftPlus function is is defined as $f(x) = ln(1 + e^x)$.}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_activationFunction_softsign.png}
		\caption{Softsign is defined as $f(x) = \frac{x}{1 + \abs{x}}$.}
	\end{subfigure}%
	~ 
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_activationFunction_relu.png}
		\caption{Rectified Linear Unit can be described as $f(x) = \begin{cases} x & x \geq 0 \\ 0 & x < 0 \end{cases}$}
	\end{subfigure}
	\caption{An excerpt of the most common activation functions used in machine learning. The rest can be found in Fig.~\ref{pic:methodology_neuralNetwork_activationFunction2}. Non-linear functions allow the neural network to solve more complex tasks. All activation functions are plotted from -4 to 4 as the most interesting features of these functions often occur around 0.}
	\label{pic:methodology_neuralNetwork_activationFunction1}
\end{figure*}

\begin{figure*}[h!]
\centering
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_activationFunction_tanh.png}
		\caption{The Tanh activation function is defined as $f(x) = tanh(x)$.}
	\end{subfigure}%
	~ 
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_activationFunction_sigmoid.png}
		\caption{The Sigmoid function is defines as $f(x) = \frac{1}{1 + e^{-x}}$.}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_activationFunction_exponential.png}
		\caption{The Exponential activation function is defined as $f(x) = e^x$.}
	\end{subfigure}%
	~ 
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_activationFunction_linear.png}
		\caption{The Linear activation function, also called identity function, is defined as $f(x) = x$.}
	\end{subfigure}
	\caption{Other common activation functions used in machine learning. Once again all activation functions are plotted from -4 to 4 for the same reason.}
	\label{pic:methodology_neuralNetwork_activationFunction2}
\end{figure*}

\newpage

\subsection{Initializer}
In neural networks the initial weights of all layers have to be set before training can begin. These weights can either be set to some constant value or initialized by random values from some distribution. Some basic initializer distributions are plotted in Fig~\ref{pic:methodology_neuralNetwork_initializerFunctions1} and Fig~\ref{pic:methodology_neuralNetwork_initializerFunctions2}.

\newpage

\begin{figure*}[h!]
	\centering
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_initializerFunctions_zeros.png}
		\caption{All output values of this function are zero.}
	\end{subfigure}%
	~ 
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_initializerFunctions_ones.png}
		\caption{All output values of this function are one.}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_initializerFunctions_constant.png}
		\caption{All output values of this function are one constant value. In this example 0.5 was chosen as the output value.}
	\end{subfigure}%
	~ 
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_initializerFunctions_randomNormal.png}
		\caption{A random normal distribution where the mean is set to 0 and the standard deviation is set to 0.05. Values closer to the mean value are more likely.}
	\end{subfigure}
	\caption{These are some of the most basic distribution most initializer functions are based on.}
	\label{pic:methodology_neuralNetwork_initializerFunctions1}
\end{figure*}

\newpage

\begin{figure*}[h!]
\centering
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_initializerFunctions_randomUniform.png}
		\caption{In a random uniform function all values between the set minimum and maximum value are equally likely.}
	\end{subfigure}%
	~ 
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/methodology_neuralNetwork_initializerFunctions_truncatedNormal.png}
		\caption{A distribution based on the normal distribution, where all values outside of two standard deviations away from the mean are redrawn.}
	\end{subfigure}
	\caption{More basic distribution initializer functions of weights and biases are often based on.}
	\label{pic:methodology_neuralNetwork_initializerFunctions2}
\end{figure*}

\subsection{Optimizer}
The objective of an optimizer is to optimize (find a local minimum of) the loss function. Some of the most widely used optimizers are:

\begin{itemize}
	\item Stochastic gradient descent (SGD)
	\item Root Mean Square Propagation (RMSProp)
	\item Adaptive Gradient Algorithm (Adagrad)
	\item Adadelta
	\item Adaptive Moment Estimation (Adam)
	\item Adamax
	\item Nesterov Adam (Nadam)
\end{itemize}

\subsection{Overfitting and Underfitting}
Overfitting occurs if the data sample is replicated too closely. One example of overfitting can be seen in Figure~\ref{pic:methodology_neuralNetwork_overfitting}. The function used is a high degree polynomial function, which has a very good fit on the noisy data originating from a linear correlation, but when testing this model on other data points, especially far from zero on the x-axis it fails to represent the original relation.

\begin{figure}[h!]
	\centering
	\includegraphics[width=4.5in]{img/methodology_neuralNetwork_overfitting.png}
	\caption{Noisy data points originating in a linear correlation (red crosses) are fitted using a high degree polynomial function (blue line), resulting in overfitting. An linear fit (light blue dashed line) has a worse fit on the given data sample, but gives better results when extrapolating.}
	\label{pic:methodology_neuralNetwork_overfitting}
\end{figure}

The goal is to find a function, that has just enough complexity to fit the data points. The opposite of overfitting is called underfitting. When underfitting a more complex problem is approximated using too simple methods, again resulting in poor results.

\section{Neural Network Implementations}
The authors decided to use a software framework called TensorFlow for the first implementation of the neural network. This has the following two advantages: using Tensorflow allows for a low effort proof of concept and it makes testing out different configurations (e.g. number of hidden layers or filters in image preprocessing) of the neural network easier.

After it has been shown that the challenge of detecting the distance to an object can be solved using machine learning, the authors plan on implementing a neural network in C++ on their own. The knowledge gained in the TensorFlow implementation will be used in the C++ implementation, which hopefully will make the work less time consuming.

\section{TensorFlow}
As machine learning has gained popularity in recent years the demand for applicable frameworks grew. One of the most popular is called TensorFlow. It was developed by Google for internal use and was published under the Apache License 2.0 on the \nth{9} of November 2015.

TensorFlow supports APIs for Python, C, C++, Go, Java, JavaScript and Swift.
Due to its popularity third party APIs for C\#, R, Scala, Rust and many more were developed.

Its use cases reach from categorizing handwritten digits to YouTube video recommendations, one of the many applications Google use it for.

Tom Hope et al. describe TensorFlow as a software framework for numerical computations based on dataflow graphs \footcite[page 6]{Hope_Learning_TensorFlow}.

\subsection{Computation graph}
To compute a value using TensorFlow a computation graph has to be constructed. In this graph each node corresponds to an operation, such as subtraction or division. By connecting these nodes via edges the output of one node can be fed as input into another node. One example of such a computation graph can be seen in Figure~\ref{pic:methodology_tensorflow_computationGraph}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=4.5in]{img/methodology_tensorflow_computationGraph.png}
	\caption{Each node represents an operation, where $const$ stands for a constant value, $add$ for addition, $mul$ for multiplication and $div$ for division. Edges, represented by arrows, connect nodes. The information shared between the nodes is described by the numbers written next to the edges. This computational graph calculates the result of the arithmetic expression $(28 * 2) + 28 / 2$.}
	\label{pic:methodology_tensorflow_computationGraph}
\end{figure}

The implementation of the computation graph, shown in Figure~\ref{pic:methodology_tensorflow_computationGraph}, in Python could look as follows:

\begin{lstlisting}[language=python]
import tensorflow as tf

a = tf.constant(28)
b = tf.constant(2)

c = tf.multiply(a, b)
d = tf.add(a, c)
e = tf.divide(d, b)

with tf.Session() as sess:
    out = sess.run(e)

print(out)
\end{lstlisting}

The first line specifies that the TensorFlow functionality should be imported. Line 3 and 4 define the two constant values and assigns them the values 28 and 2 respectively. In line 6 to 8 the other nodes of the graph are specified. E.g. in line 6 a new node, named $c$, is created and the output of node $a$ and node $b$ are connected as its input. To perform the calculation described by the graph a new session is created in line 10. Finally the output of the graph (node $e$) is specified in line 11, the result is calculated and printed in line 13.

TensorFlow allows for another way of specifying a graph with these arithmetic operations:

\begin{lstlisting}[language=python]
import tensorflow as tf

a = tf.constant(28)
b = tf.constant(2)

e = (a * b + a) / b

with tf.Session() as sess:
    out = sess.run(e)

print(out)
\end{lstlisting}

This code is equivalent to the first one, but uses syntactic sugar to shorten line 6 to 8 in the first code block into line 6. At this point it should be noted that while it might look like it line 6 does not calculate anything. It simply describes how the computational graph should look. The answer (42) is calculated in the session in line 9.

Using the same principle, but different functions TensorFlow allows the creation of complex neural networks in a simple fashion.

\subsection{Alternatives to Tensorflow}
TensorFlow offers some abstraction libraries, such as Keras. As some code snippets are used very frequently and with only slight variation when implementing a Neural Network, Keras offers these code blocks as predefined functions, making development easier for ``standard'' use cases.

For example Keras provides several different layers, that can be used to put together a neural network. Table~\ref{tab:methodology_tensorflow_alternativesToTensorflow_kerasLayers} describes just some of the available layers.

\begin{center}
	\begin{table}[h!]
		\begin{tabular}{| l | l |}
			\hline
			\bfseries Name & \bfseries Description \\
			\hline
			Dense & regular densely connected layer \\
			\hline
			Activation & Applies an activation function to an output \\
			\hline
			Dropout & Applies Dropout to the input \\
			\hline
			Flatten & Flattens the input down to shape \\
			\hline
			Conv1D & 1D convolution layer (e.g. temporal convolution)  \\
			\hline
			MaxPooling1D & Max pooling operation for temporal data \\
			\hline
			LocallyConnected1D & Locally-connected layer for 1D inputs \\
			\hline
			SimpleRNN & Fully-connected RNN where the output is to be fed back to input \\
			\hline
			
		\end{tabular}
		\caption{Short description of layers available in Keras, that can be used to assemble a neural network, with little effort.}
		\label{tab:methodology_tensorflow_alternativesToTensorflow_kerasLayers}
	\end{table}
\end{center}

\newpage

Another feature Keras offers is image preprocessing. In comparison to the authors use of this phrase, Keras offers transformations of the image that alter the image only slightly, which prevents overfitting, when using only a small input data set of images. Examples of the transformations offered are: rotating the image, shifting the image along the vertical or horizontal axis, changing the brightness of the image, zooming, flipping the image vertically or horizontally and rescaling the image.

\vspace{0.5cm}

Other machine learning frameworks are:

\begin{itemize}
	\item PyTorch
	\item Caffe
	\item Microsoft Cognitive toolkit (CNTK)
	\item Caffe2
	\item MXNet
	\item Torch
	\item Theano
	\item DeepLearning4j
\end{itemize}

\filbreak
